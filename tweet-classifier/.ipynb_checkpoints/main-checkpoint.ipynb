{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim, logging, nltk, re, string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and drop NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_train = pd.read_csv(\"data/train.csv\", dtype=str, encoding='utf-8', sep=\",\", header=0, index_col=None, na_values='Not Available').dropna()\n",
    "tweets_test = pd.read_csv(\"data/test.csv\", dtype=str, encoding='utf-8', sep=\",\", header=0, index_col=None)\n",
    "tweets_test.rename(columns = {'Category':'Tweet'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot number of tweets in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f56820de518>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6Hy+ATjr/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56820cb2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "tweets_train.Category.value_counts().plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenisation function and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = [\"a\", \"about\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\",\n",
    "            \"before\", \"being\", \"between\", \"both\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"during\", \"each\",\n",
    "            \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "            \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\",\n",
    "            \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"of\",\n",
    "            \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"own\", \"shan't\", \"she\", \"she'd\",\n",
    "            \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\",\n",
    "            \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\",\n",
    "            \"they've\", \"this\", \"those\", \"through\", \"to\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\",\n",
    "            \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "            \"which\", \"while\", \"who\", \"who's\", \"whom\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "            \"your\", \"yours\", \"yourself\", \"yourselves\", \"above\", \"again\", \"against\", \"aren't\", \"below\", \"but\", \"can't\",\n",
    "            \"cannot\", \"couldn't\", \"didn't\", \"doesn't\", \"don't\", \"down\", \"few\", \"hadn't\", \"hasn't\", \"haven't\", \"if\",\n",
    "            \"isn't\", \"mustn't\", \"not\", \"no\", \"nor\", \"off\", \"out\", \"over\", \"shouldn't\", \"same\", \"too\", \"under\", \"why\",\n",
    "            \"why's\", \"won't\", \"wouldn't\"]\n",
    "\n",
    "RE_HTTP = re.compile(\"http(s)?://[/\\.a-z0-9]+\")\n",
    "RE_HASHTAG = re.compile(\"[@#][_a-z0-9]+\")\n",
    "RE_EMOTICONS = re.compile(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\")\n",
    "\n",
    "def prepare_text(text):\n",
    "    replacers = {'&nbsp;': ' ', '&lt;': '<', '&gt;': '>', '&amp;': '&', '&pound;': u'£', \n",
    "                 '&euro;': u'€', '&copy;': u'©', '&reg;': u'®'}\n",
    "    for r in replacers.keys():\n",
    "        text = text.replace(r, replacers[r])\n",
    "    return text\n",
    "\n",
    "def contains_punctuation(text, translator):\n",
    "    return (text.translate(translator) != text)\n",
    "    \n",
    "def tokenize_tweet(text):\n",
    "    # replace broken characters\n",
    "    text = prepare_text(text)\n",
    "    #tokenize with tweet tokenizer\n",
    "    tknz = nltk.tokenize.TweetTokenizer()\n",
    "    tokens = tknz.tokenize(text.lower())\n",
    "    # drop urls\n",
    "    tokens = [token for token in tokens if not RE_HTTP.search(token)]\n",
    "    # drop hashtags\n",
    "    tokens = [token for token in tokens if not RE_HASHTAG.search(token)]\n",
    "    # drop stopwords\n",
    "    #tokens = [token for token in tokens if token not in stopwords]\n",
    "    # drop punctuation (but not emoticons!)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [token for token in tokens if RE_EMOTICONS.search(token) or not contains_punctuation(token, translator)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tokenized = [tokenize_tweet(x) for x in tweets_train['Tweet'] if isinstance(x, str)]\n",
    "test_tokenized = [tokenize_tweet(x) for x in tweets_test['Tweet'] if isinstance(x, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ios', '9', 'app', 'transport', 'security', 'mm', 'need', 'to', 'check', 'if', 'my', '3rd', 'party', 'network', 'pod', 'supports', 'it'], ['mar', 'if', 'you', 'have', 'an', 'ios', 'device', 'you', 'should', 'download', 'our', 'app', 'too'], ['my', 'phone', 'does', 'not', 'run', 'on', 'latest', 'ios', 'which', 'may', 'account', 'for', 'problem', 'the', 'other', 'day', 'time', 'it', 'was', 'replaced'], ['not', 'sure', 'how', 'to', 'start', 'your', 'publication', 'on', 'ios', 'be', 'live', 'helping', 'with', 'ask', 'me', 'anything', 'sessions', 'today', 'and', 'friday'], ['two', 'dollar', 'tuesday', 'is', 'here', 'with', 'forklift', '2', 'quickkey', 'for', 'ios', 'and', 'suite', 'for', 'pages', 'for', 'just', 'today'], ['if', 'not', 'already', 'signed', 'up', 'to', 'test', 'my', 'ios', 'game', 'nows', 'your', 'chance']]\n"
     ]
    }
   ],
   "source": [
    "print(train_tokenized[0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-19 15:51:23,987 : INFO : collecting all words and their counts\n",
      "2017-01-19 15:51:23,989 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-19 15:51:24,037 : INFO : collected 10431 word types from a corpus of 97575 raw words and 5422 sentences\n",
      "2017-01-19 15:51:24,041 : INFO : Loading a fresh vocabulary\n",
      "2017-01-19 15:51:24,074 : INFO : min_count=3 retains 3183 unique words (30% of original 10431, drops 7248)\n",
      "2017-01-19 15:51:24,075 : INFO : min_count=3 leaves 88817 word corpus (91% of original 97575, drops 8758)\n",
      "2017-01-19 15:51:24,108 : INFO : deleting the raw counts dictionary of 10431 items\n",
      "2017-01-19 15:51:24,109 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2017-01-19 15:51:24,111 : INFO : downsampling leaves estimated 67877 word corpus (76.4% of prior 88817)\n",
      "2017-01-19 15:51:24,114 : INFO : estimated required memory for 3183 words and 200 dimensions: 6684300 bytes\n",
      "2017-01-19 15:51:24,133 : INFO : resetting layer weights\n",
      "2017-01-19 15:51:24,213 : INFO : training model with 4 workers on 3183 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=4\n",
      "2017-01-19 15:51:24,214 : INFO : expecting 5422 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-19 15:51:25,224 : INFO : PROGRESS: at 11.26% examples, 228757 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-19 15:51:26,235 : INFO : PROGRESS: at 22.18% examples, 224300 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-19 15:51:27,236 : INFO : PROGRESS: at 33.78% examples, 228183 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-19 15:51:28,245 : INFO : PROGRESS: at 45.05% examples, 227837 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-19 15:51:29,254 : INFO : PROGRESS: at 57.33% examples, 231951 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-19 15:51:30,288 : INFO : PROGRESS: at 69.97% examples, 234758 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-19 15:51:31,334 : INFO : PROGRESS: at 82.25% examples, 235435 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-19 15:51:32,357 : INFO : PROGRESS: at 94.53% examples, 236581 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-19 15:51:32,695 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-19 15:51:32,706 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-19 15:51:32,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-19 15:51:32,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-19 15:51:32,764 : INFO : training on 2927250 raw words (2035983 effective words) took 8.5s, 238328 effective words/s\n",
      "2017-01-19 15:51:32,766 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(train_tokenized, size=200, window=4, min_count=3, iter=30, workers=4)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count average word vector in tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.layer_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, text) for text in text_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_word_average = word_averaging_list(model.wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(model.wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06783559 -0.07318275 -0.04694032 ..., -0.0491212  -0.01461332\n",
      "   0.00671249]\n",
      " [-0.00764339 -0.09340752 -0.07280925 ..., -0.0804297  -0.01822649\n",
      "  -0.00611928]\n",
      " [-0.04565764 -0.15492409 -0.17064734 ...,  0.06155074  0.09368764\n",
      "   0.1140742 ]\n",
      " ..., \n",
      " [ 0.02817192 -0.04598491 -0.00250292 ..., -0.04012828  0.01079136\n",
      "  -0.00886637]\n",
      " [-0.04565764 -0.15492409 -0.17064734 ...,  0.06155074  0.09368764\n",
      "   0.1140742 ]\n",
      " [ 0.02861984 -0.12866679 -0.09564702 ..., -0.10849581  0.03107977\n",
      "  -0.0278804 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_word_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create classification model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(n_jobs=-1, C=1e4)\n",
    "\n",
    "logreg = logreg.fit(X_train_word_average, tweets_train['Category'])\n",
    "predicted = logreg.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export predicted values to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Id  Category\n",
      "0     628949369883000832  positive\n",
      "1     628976607420645377  positive\n",
      "2     629023169169518592  positive\n",
      "3     629179223232479232  positive\n",
      "4     629186282179153920   neutral\n",
      "5     629226490152914944   neutral\n",
      "6     629345637155360768  positive\n",
      "7     629394528336637953  positive\n",
      "8     629650766580609026  positive\n",
      "9     629797991826722816   neutral\n",
      "10    630159517058142208  positive\n",
      "11    630542330827771904   neutral\n",
      "12    630636736746422272  positive\n",
      "13    630807124872970240  positive\n",
      "14    630818265799921664  positive\n",
      "15    630909171437801472  negative\n",
      "16    630982270409572352   neutral\n",
      "17    631104156187627520   neutral\n",
      "18    631223085476261890  negative\n",
      "19    631368262979297281   neutral\n",
      "20    631521079245307904  positive\n",
      "21    631543121407442946   neutral\n",
      "22    631696872323850240  positive\n",
      "23    631792365590695936  positive\n",
      "24    631842974268305408  positive\n",
      "25    631843393971204097  positive\n",
      "26    631936716522278912   neutral\n",
      "27    632374683334258688   neutral\n",
      "28    632536348419690496   neutral\n",
      "29    632805868334153728   neutral\n",
      "...                  ...       ...\n",
      "3970  639287851725619200  positive\n",
      "3971  639319688070086656  positive\n",
      "3972  639431507363414016  positive\n",
      "3973  639564269420331008  positive\n",
      "3974  639639485207019520  positive\n",
      "3975  639645064633823233  positive\n",
      "3976  639666970229473280  positive\n",
      "3977  639808591529033729  positive\n",
      "3978  639821082497818625  positive\n",
      "3979  640020822313304064   neutral\n",
      "3980  640173861078626304  positive\n",
      "3981  640212997596549120   neutral\n",
      "3982  640475498137518080   neutral\n",
      "3983  640477314023723010   neutral\n",
      "3984  640689013788176384  positive\n",
      "3985  640704945134661636  positive\n",
      "3986  640705879520636928  positive\n",
      "3987  640728268254019584  positive\n",
      "3988  640731830300340224  positive\n",
      "3989  640758594959450112  positive\n",
      "3990  641064131706122240  positive\n",
      "3991  641087370872422401  positive\n",
      "3992  641089872426631168   neutral\n",
      "3993  641254971401502720   neutral\n",
      "3994  641371402348679168   neutral\n",
      "3995  641411385700712448  positive\n",
      "3996  641452712098406400  positive\n",
      "3997  635369700298498048   neutral\n",
      "3998  635769805279248384  positive\n",
      "3999  635930169241374720   neutral\n",
      "\n",
      "[4000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "predicted_df = pd.DataFrame(predicted, columns=['Category'])\n",
    "id_df = pd.DataFrame(tweets_test['Id'][0:len(test_tokenized)])\n",
    "final = pd.concat([id_df, predicted_df], axis=1)\n",
    "print(final)\n",
    "final.to_csv(path_or_buf=\"data/my_submission.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code was used to test accuracy on train data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def print_accuracy(actual, predicted):\n",
    "    print('Trafność klasyfikacji %s' % accuracy_score(actual, predicted))\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    print('Macierz pomyłek\\n %s\\n' % cm)\n",
    "    list_of_labels = list(set(actual))\n",
    "    print(\"            Positive    Neutral     Negative   \")\n",
    "    print(\"F1       \", f1_score(actual, predicted, average=None, pos_label=None, labels=list_of_labels))\n",
    "    print(\"Precision\", precision_score(actual, predicted, average=None, pos_label=None, labels=list_of_labels))\n",
    "    print(\"Recall   \", recall_score(actual, predicted, average=None, pos_label=None, labels=list_of_labels))\n",
    "    \n",
    "    \n",
    "xtr, xte, ytr, yte = train_test_split(tweets_train['Tweet'], tweets_train['Category'], test_size=0.1, random_state=41)\n",
    "xtrt = [tokenize_tweet(x) for x in xtr]\n",
    "xtet = [tokenize_tweet(x) for x in xte]\n",
    "xtra = word_averaging_list(model.wv,xtrt)\n",
    "xtea = word_averaging_list(model.wv,xtet)\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=-1, C=1e4)\n",
    "logreg = logreg.fit(xtra, ytr)\n",
    "predicted = logreg.predict(xtea)\n",
    "print_accuracy(yte, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
